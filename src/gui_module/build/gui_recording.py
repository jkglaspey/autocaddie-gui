
# This file was generated by the Tkinter Designer by Parth Jadhav
# https://github.com/ParthJadhav/Tkinter-Designer


from pathlib import Path
from gui_module.build import gui_generating_results
import json
import threading
from PIL import Image, ImageTk
from data_processing.serial_bluetooth_communication import stop_bluetooth
from data_processing.record_imu import send_end_signal
from algorithms.cv.convert_video_to_display import close_cameras, get_frame_from_camera
from algorithms.cv.camera_recorder import start_recording, stop_recording, change_dims
import time

# Explicit imports to satisfy Flake8
from tkinter import Tk, Canvas, Entry, Text, Button, PhotoImage

OUTPUT_PATH = Path(__file__).parent
ASSETS_PATH = OUTPUT_PATH / Path(r".\assets\frame8")

def relative_to_assets(path: str) -> Path:
    return ASSETS_PATH / Path(path)

def save_window_state(width, height, fullscreen, x, y, state):
    with open(r"gui_module\build\assets\window_state.json", "w") as f:
        json.dump({"width": width, "height": height, "fullscreen": fullscreen, "x": x, "y": y, "maximized": state}, f)

def load_window_state():
    try:
        with open(r"gui_module\build\assets\window_state.json", "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return None
    
def create_window(width, height, fullscreen, x, y, maximized):
    window = Tk()
    window.geometry(f"{width}x{height}")
    window.configure(bg="#FFFFFF")
    window.geometry("+{}+{}".format(x, y))

    # Maximized or fullscreen?
    if maximized:
        window.state('zoomed')
    if fullscreen:
        window.attributes("-fullscreen", True)
    
    # Save window state before closing
    window.protocol("WM_DELETE_WINDOW", lambda: close_window(window, width, height, x, y, True))
    
    return window

def close_window(window, width, height, x, y, closeBluetooth):
    if window.attributes("-fullscreen") == 0:
            x, y = get_window_position(window)
    save_window_state(width, height, window.attributes("-fullscreen"), x, y, window.state() == 'zoomed')
    if closeBluetooth is True:
        global terminate_bluetooth, ser_out
        terminate_bluetooth = True
        send_end_signal()
        stop_bluetooth(ser_out)
    window.destroy()

def get_window_position(window):
    geometry_string = window.geometry()
    x, y = map(int, geometry_string.split('+')[1:])
    return x, y

def window_event(window):
    if window.state() != 'zoomed':
        return window.winfo_width(), window.winfo_height()
    else:
        return 0, 0

def notify_end_bluetooth():
    print("Bluetooth ended!")
    global terminate_bluetooth, imu_received, ser_out, text_states, video_received
    imu_received = True
    terminate_bluetooth = True
    stop_bluetooth(ser_out)
    # Modify text states
    text_states["text_mcu"] = False
    text_states["text_status"] = False
    if video_received == True:
        finish_recording()

global start_recording_event
start_recording_event = threading.Event()
def notify_start_videos():
    global save_image, start_recording_event
    save_image = True
    start_recording_event.set()

def notify_end_videos():
    print("Videos ended!")
    global video_received, save_image, imu_received
    video_received = True
    save_image = False
    if imu_received == True:
        finish_recording()

def update_camera_feed(frame, canvas, window, width, height, rectangle, id):
    window.after(0, update_camera_frames(frame, canvas, width, height, rectangle, id))

def update_camera_frames(frame, canvas, width, height, rectangle, id):
    global canvas_width, canvas_height
    if id == 0:
        captured_frame = frame
        canvas.itemconfig(rectangle, image=captured_frame)
        canvas.rectangle_1 = captured_frame  # Prevent garbage collection
        canvas.coords(rectangle, canvas_width * 0.020, canvas_height * 0.429)
    else:
        captured_frame = frame
        canvas.itemconfig(rectangle, image=captured_frame)
        canvas.rectangle_2 = captured_frame  # Prevent garbage collection
        canvas.coords(rectangle, canvas_width * 0.517, canvas_height * 0.429)


global end_event
end_event = threading.Event()
def finish_recording():
    print("Finished Recording Data!")
    global finished_recording, end_event
    finished_recording = True
    end_event.set()

def start_recording_thread(recorder_thread_0, recorder_thread_1, i1, i2, width, height):
    recorder_thread_0 = start_recording(i1, r"data_processing\video_data\output_1.mp4", width, height, 0)
    recorder_thread_1 = start_recording(i2, r"data_processing\video_data\output_2.mp4", width, height, 1)
    return recorder_thread_0, recorder_thread_1

def stop_recording_thread(recorder_thread_0, recorder_thread_1):
    if recorder_thread_0:
        stop_recording(recorder_thread_0)
    if recorder_thread_1:
        stop_recording(recorder_thread_1)

def main(ser_out_ref, camera_1, camera_2):
    global ser_out
    ser_out = ser_out_ref

    saved_state = load_window_state()
    global width, height, x, y
    width = 0
    height = 0
    x = 0
    y = 0
    if saved_state:
        width, height, fullscreen, x, y, maximized = saved_state["width"], saved_state["height"], saved_state["fullscreen"], saved_state["x"], saved_state["y"], saved_state["maximized"]
    else:
        width, height, fullscreen, x, y, maximized = 797, 448, False, 0, 0, False
    
    window = create_window(width, height, fullscreen, x, y, maximized)

    global window_ref
    window_ref = window

    # Recording status
    global imu_received, video_received, finished_recording
    imu_received = False
    video_received = False
    finished_recording = False

    # Saving images?
    global save_image
    save_image = False

    # Reference to cameras
    global cameras
    cameras = []
    cameras.append(camera_1)
    cameras.append(camera_2)
            
    # Fullscreen
    def toggle_fullscreen(event=None):
        state = not window.attributes("-fullscreen")
        window.attributes("-fullscreen", state)
        return "break"

    def end_fullscreen(event=None):
        window.attributes("-fullscreen", False)
        return "break"

    # Bind F11 key to toggle fullscreen
    window.bind("<F11>", toggle_fullscreen)
    # Bind Escape key to end fullscreen
    window.bind("<Escape>", end_fullscreen)

    # Body
    canvas = Canvas(
        window,
        bg = "#FFFFFF",
        height = 448,
        width = 797,
        bd = 0,
        highlightthickness = 0,
        relief = "ridge"
    )
    canvas.pack(fill="both", expand=True)

    # Initialize dimensions
    global camera_width, camera_height, canvas_width, canvas_height
    canvas_width = canvas.winfo_width()
    canvas_height = canvas.winfo_height()
    camera_width = (int)(canvas_width * 0.464)
    camera_height = (int)(canvas_height * 0.535)
    if camera_width == 0:
        camera_width = 1
    if camera_height == 0:
        camera_height = 1

    # Resize background image
    def resize_background(event=None):

        # Resize the image to fit the canvas size
        resized_image_1 = image_image_1.resize((canvas_width, canvas_height))

        # Convert the resized image to a Tkinter-compatible format
        photo_image_1 = ImageTk.PhotoImage(resized_image_1)

        # Update the canvas with the resized image
        canvas.itemconfig(image_1, image=photo_image_1)
        canvas.image_1 = photo_image_1  # Keep a reference to prevent garbage collection

    # Resize elements in window
    def resize_canvas(event=None):

        # Window
        temp_width, temp_height = window_event(window)
        if temp_width > 0 and temp_height > 0:
            width = temp_width
            height = temp_height
        if window.attributes("-fullscreen") == 0:
            x, y = get_window_position(window)

        # Get the size of the canvas
        global canvas_width, canvas_height
        canvas_width = canvas.winfo_width()
        canvas_height = canvas.winfo_height()

        # Resize the background image
        resize_background()

        # Rectangles
        new_cords = [canvas_width * 0.020, canvas_height * 0.107, canvas_width * 0.484, canvas_height * 0.393]
        canvas.coords(rectangle_3, *new_cords)
        new_cords = [canvas_width * 0.516, canvas_height * 0.107, canvas_width * 0.98, canvas_height * 0.393]
        canvas.coords(rectangle_4, *new_cords)

        # Text
        text_x = canvas_width / 18.667
        text_y = canvas_height / 18.667
        font_size = int(min(text_x, text_y))
        canvas.itemconfig(text_2, font=("Inter", font_size * -1))
        canvas.coords(text_2, canvas_width * 0.179, canvas_height * 0.183)
        canvas.itemconfig(text_3, font=("Inter", font_size * -1))
        canvas.coords(text_3, canvas_width * 0.683, canvas_height * 0.183)
        canvas.itemconfig(text_5, font=("Inter", font_size * -1))
        canvas.coords(text_5, canvas_width * 0.02, canvas_height * 0.027)

        # Images
        global camera_width, camera_height
        camera_width = (int)(canvas_width * 0.464)
        camera_height = (int)(canvas_height * 0.535)
        nonlocal recorder_thread_0, recorder_thread_1
        if recorder_thread_0:
            change_dims(recorder_thread_0, camera_width, camera_height)
        if recorder_thread_1:
            change_dims(recorder_thread_1, camera_width, camera_height)

        # Center Text 2 and Text 3
        rect_3_x1, rect_3_y1, rect_3_x2, rect_3_y2 = canvas.coords(rectangle_3)
        rect_3_center_x = (rect_3_x1 + rect_3_x2) / 2
        rect_3_center_y = (rect_3_y1 + rect_3_y2) / 2
        text_2_bbox = canvas.bbox(text_2)
        text_2_width = text_2_bbox[2] - text_2_bbox[0]
        text_2_height = text_2_bbox[3] - text_2_bbox[1]
        text_2_x = rect_3_center_x - text_2_width / 2
        text_2_y = rect_3_center_y - text_2_height / 2
        canvas.coords(text_2, text_2_x, text_2_y)

        rect_4_x1, rect_4_y1, rect_4_x2, rect_4_y2 = canvas.coords(rectangle_4)
        rect_4_center_x = (rect_4_x1 + rect_4_x2) / 2
        rect_4_center_y = (rect_4_y1 + rect_4_y2) / 2
        text_3_bbox = canvas.bbox(text_3)
        text_3_width = text_3_bbox[2] - text_3_bbox[0]
        text_3_height = text_3_bbox[3] - text_3_bbox[1]
        text_3_x = rect_4_center_x - text_3_width / 2
        text_3_y = rect_4_center_y - text_3_height / 2
        canvas.coords(text_3, text_3_x, text_3_y)

    # Bind resizing events
    canvas.bind("<Configure>", resize_canvas)

    # Switch dot states to display "waiting" to the user
    global text_states
    text_states = {
        "text_mcu": True,
        "text_status": True
    }
    def update_waiting_text(text_item, initial_text, delay, id):
        dots = 0

        def update_text():
            if text_states[id]:
                nonlocal dots
                new_text = initial_text[:-3] + "." * (dots % 4)
                canvas.itemconfig(text_item, text=new_text)
                dots += 1
                if not imu_received and window.winfo_exists():
                    canvas.after(delay, lambda: update_text() if window.winfo_exists() else None)
            # Only 1 time text will be animated. Use this to update boxes
            elif id == "text_mcu":
                canvas.itemconfig(text_3, text="MCU\nReady!")
                canvas.itemconfig(text_3, fill="#FFFFFF")
                canvas.itemconfig(rectangle_4, fill="#45AC2C")
                canvas.itemconfig(text_2, text="STATUS\nCompleted!")
                canvas.itemconfig(text_2, fill="#FFFFFF")
                canvas.itemconfig(rectangle_3, fill="#45AC2C")

        update_text()

    # Image 1
    image_image_1 = Image.open(relative_to_assets("image_1.png"))
    photo_image_1 = ImageTk.PhotoImage(image_image_1)
    image_1 = canvas.create_image(0, 0, anchor="nw", image=photo_image_1)

    # Rectangle 1 (REPLACE WITH IMAGE)
    #rectangle_1 = canvas.create_rectangle(
    #    16.0,
    #    192.0,
    #    386.0,
    #    432.0,
    #    fill="#1E1E1E",
    #    outline="")
    dark_black_image = Image.new("RGB", (370, 240), "#1E1E1E")
    photo_image_dark_black = ImageTk.PhotoImage(dark_black_image)
    rectangle_1 = canvas.create_image(16, 192, anchor="nw", image=photo_image_dark_black)

    # Rectangle 2 (REPLACE WITH IMAGE)
    #rectangle_2 = canvas.create_rectangle(
    #    411.0,
    #    192.0,
    #    781.0,
    #    432.0,
    #    fill="#1E1E1E",
    #    outline="")
    rectangle_2 = canvas.create_image(411, 192, anchor="nw", image=photo_image_dark_black)

    # Rectangle 3
    rectangle_3 = canvas.create_rectangle(
        16.26530647277832,
        48.0,
        386.2653064727783,
        176.0,
        fill="#FF0000",
        outline="")

    # Rectangle 4
    rectangle_4 = canvas.create_rectangle(
        411.0,
        48.0,
        781.0,
        176.0,
        fill="#FFFFFF",
        outline="")

    # Text 2
    text_2 = canvas.create_text(
        143.0,
        82.0,
        anchor="nw",
        text="STATUS\nRecording...",
        fill="#000000",
        font=("Inter", 24 * -1)
    )
    update_waiting_text(text_2, "STATUS\nRecording...", 1000, "text_status")

    # Text 3
    text_3 = canvas.create_text(
        544.0,
        82.0,
        anchor="nw",
        text="MCU\nRecording...",
        fill="#000000",
        font=("Inter", 24 * -1)
    )
    update_waiting_text(text_3, "MCU\nRecording...", 1000, "text_mcu")

    # Text 5
    text_5 = canvas.create_text(
        16.0,
        12.0,
        anchor="nw",
        text="AutoCaddie",
        fill="#1E1E1E",
        font=("Inter SemiBold", 24 * -1)
    )

    recorder_thread_0 = None
    recorder_thread_1 = None
    def start_recording_local():

        # Start recording
        nonlocal recorder_thread_0, recorder_thread_1
        recorder_thread_0.set_recording_to_true()
        recorder_thread_1.set_recording_to_true()
        
        # Sleep for 3 seconds (in this thread!)
        time.sleep(3)

        # Call the camera to stop recording
        stop_recording_thread(recorder_thread_0, recorder_thread_1)

        # Cameras finished! Give 1 second, then set variable
        time.sleep(1)
        end_thread.start()
        notify_end_videos()

    def initialize_camera_thread():
        nonlocal recorder_thread_0, recorder_thread_1
        global camera_width, camera_height
        recorder_thread_0, recorder_thread_1 = start_recording_thread(recorder_thread_0, recorder_thread_1, camera_1, camera_2, camera_width, camera_height)
        recorder_thread_0.keep_reference(window, canvas, rectangle_1)
        recorder_thread_1.keep_reference(window, canvas, rectangle_2)
        global save_image, start_recording_event
        while save_image is False:
            start_recording_event.wait()
        start_recording_local()
    record_camera_thread = threading.Thread(target = initialize_camera_thread)
    record_camera_thread.start()

    def wait_to_end():
        global end_event, finish_recording
        while not finish_recording:
            end_event.wait()
        window.after(0,next_window)
    end_thread = threading.Thread(target = wait_to_end)

    def next_window():
        close_cameras(cameras)
        close_window(window_ref, width, height, x, y, False)
        gui_generating_results.main()
        
    # Iterate until data is received
    window.mainloop()

if __name__ == "__main__":
    main(None, None, None)